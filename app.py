import streamlit as st
import pandas as pd
import numpy as np
from scipy.stats import ttest_ind, chi2_contingency
import statsmodels.api as sm
from statsmodels.formula.api import ols
from fpdf import FPDF
import plotly.express as px 
import plotly.io as pio 
import warnings
import io 

warnings.filterwarnings('ignore')

# --- 2. SÄ°STEMÄ°N GEREKLÄ° SÃœTUNLARI (ÅABLON Ä°Ã‡Ä°N) ---
NUMERIC_COLUMNS = [
    'yas', 'gebelik_haftasi', 
    'korku_vas_baseline', 'korku_olcek_baseline',
    'korku_vas_4cm', 'korku_olcek_4cm',
    'korku_vas_8cm', 'korku_olcek_8cm',
    'endise_oxford_baseline', 'endise_oxford_son_test'
]
CATEGORIC_COLUMNS = [
    'grup', 'egitim_durumu', 'dogum_baslangici', 'medeni_durum', 
    'gelir_duzeyi', 'calisma_durumu', 'planli_gebelik_mi'
]
ALL_REQUIRED_COLUMNS = NUMERIC_COLUMNS + CATEGORIC_COLUMNS

# --- 3. YENÄ° ÅABLON OLUÅTURMA FONKSÄ°YONU ---
@st.cache_data 
def create_template_excel():
    df_template = pd.DataFrame(columns=ALL_REQUIRED_COLUMNS)
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_template.to_excel(writer, sheet_name='Veri_Giris_Sayfasi', index=False)
    return output.getvalue()

# --- 4. YARDIMCI PDF FONKSÄ°YONLARI ---
def normalize_for_pdf(text):
    text = str(text) 
    replacements = {
        'Ä°': 'I', 'Ä±': 'i', 'Å': 'S', 'ÅŸ': 's', 'Ä': 'G', 'ÄŸ': 'g',
        'Ãœ': 'U', 'Ã¼': 'u', 'Ã–': 'O', 'Ã¶': 'o', 'Ã‡': 'C', 'Ã§': 'c'
    }
    for tr_char, en_char in replacements.items():
        text = text.replace(tr_char, en_char)
    return text

def create_pdf_report(results, charts):
    pdf = FPDF()
    pdf.add_page()
    
    pdf.set_font("Arial", "B", 16)
    pdf.cell(0, 10, "Ebelik Arastirmasi Istatistiksel Analiz Raporu", ln=True, align="C")
    pdf.ln(5) 
    
    # --- FAZ 1 Raporu ---
    pdf.set_font("Arial", "B", 14)
    pdf.cell(190, 10, "FAZ 1: Baslangic Denkligi Raporu", ln=True)
    pdf.set_font("Arial", "", 10)
    
    if results['faz1_is_denk']:
        pdf.set_text_color(0, 100, 0); pdf.multi_cell(190, 5, normalize_for_pdf("SONUC: Randomizasyon BASARILI (Tum p > 0.05)"))
        pdf.set_text_color(0, 0, 0); pdf.multi_cell(190, 5, normalize_for_pdf(
            "Yorum: Gruplar arasi anlamli bir baslangic farki bulunamamistir. "
            "Bu, gruplarin homojen (denk) oldugunu ve arastirmanin ic gecerliliginin "
            "yuksek oldugunu gosterir."
        ))
    else:
        pdf.set_text_color(255, 165, 0); pdf.multi_cell(190, 5, normalize_for_pdf("SONUC: Randomizasyon BASARISIZ (p < 0.05)"))
        pdf.set_text_color(0, 0, 0); failed_vars_str = ", ".join(results['faz1_failed_vars_display_names'])
        pdf.multi_cell(190, 5, normalize_for_pdf(
            f"Neden Kaynakli?: Analiz, '{failed_vars_str}' degisken(ler)i acisindan anlamli bir fark tespit etmistir."
        ))
    pdf.ln(5)
    
    # --- FAZ 2 Raporu ---
    pdf.set_font("Arial", "B", 14)
    pdf.cell(190, 10, "FAZ 2: Hipotez Testleri Raporu (ANCOVA)", ln=True)
    
    if results['correction_applied']:
        pdf.set_font("Arial", "B", 10); pdf.set_text_color(200, 0, 0)
        pdf.multi_cell(190, 5, normalize_for_pdf(
            f"DIKKAT: ISTATISTIKSEL DUZELTME UYGULANDI.\nFAZ 1'deki denklik hatasi nedeniyle su degisken(ler) analize 'kovaryant' "
            f"olarak eklenmistir: {results['correction_applied']}"
        ))
        pdf.set_text_color(0, 0, 0); pdf.ln(2)

    # FAZ 2 SonuÃ§larÄ±
    pdf.set_font("Arial", "B", 12); pdf.cell(190, 8, "[H1: Latent Faz Korku]", ln=True)
    pdf.set_font("Arial", "", 10)
    pdf.cell(190, 5, normalize_for_pdf(f"- VAS Sonucu: {'DESTEKLENDI' if results['h1_vas_p'] < 0.05 else 'Reddedildi'} (p-degeri: {results['h1_vas_p']:.6f})"), ln=True)
    pdf.cell(190, 5, normalize_for_pdf(f"- Dogum Korku Olcegi Sonucu: {'DESTEKLENDI' if results['h1_olcek_p'] < 0.05 else 'Reddedildi'} (p-degeri: {results['h1_olcek_p']:.6f})"), ln=True)
    
    pdf.set_font("Arial", "B", 12); pdf.cell(190, 8, "[H2: Aktif Faz Korku]", ln=True)
    pdf.set_font("Arial", "", 10)
    pdf.cell(190, 5, normalize_for_pdf(f"- VAS Sonucu: {'DESTEKLENDI' if results['h2_vas_p'] < 0.05 else 'Reddedildi'} (p-degeri: {results['h2_vas_p']:.6f})"), ln=True)
    pdf.cell(190, 5, normalize_for_pdf(f"- Dogum Korku Olcegi Sonucu: {'DESTEKLENDI' if results['h2_olcek_p'] < 0.05 else 'Reddedildi'} (p-degeri: {results['h2_olcek_p']:.6f})"), ln=True)
    
    pdf.set_font("Arial", "B", 12); pdf.cell(190, 8, "[H3: Endise Duzeyi]", ln=True)
    pdf.set_font("Arial", "", 10)
    pdf.cell(190, 5, normalize_for_pdf(f"- Oxford Endise Olcegi Sonucu: {'DESTEKLENDI' if results['h3_oxford_p'] < 0.05 else 'Reddedildi'} (p-degeri: {results['h3_oxford_p']:.6f})"), ln=True)
    pdf.ln(5)
    
    # --- Nihai Yorum ---
    pdf.set_font("Arial", "B", 14); pdf.cell(190, 10, "Nihai Rapor Yorumu (Analist Ozeti)", ln=True)
    pdf.set_font("Arial", "", 10)
    pdf.multi_cell(190, 5, normalize_for_pdf(results['final_report_text']))
    
    # --- Sayfa 3: Sosyodemografik Grafikler (EK A) ---
    pdf.add_page()
    pdf.set_font("Arial", "B", 14)
    pdf.cell(190, 10, "EK A: Sosyodemografik Dagilimlar (Dashboard Grafikleri)", ln=True)
    try:
        img_medeni = pio.to_image(charts['fig_pie_medeni'], format="png"); img_gelir = pio.to_image(charts['fig_pie_gelir'], format="png")
        img_calisma = pio.to_image(charts['fig_pie_calisma'], format="png"); img_plan = pio.to_image(charts['fig_pie_plan'], format="png")
        pdf.image(io.BytesIO(img_medeni), w=90, h=65, x=10); pdf.image(io.BytesIO(img_gelir), w=90, h=65, x=110)
        pdf.ln(70); pdf.image(io.BytesIO(img_calisma), w=90, h=65, x=10); pdf.image(io.BytesIO(img_plan), w=90, h=65, x=110)
    except Exception as e:
        pdf.set_text_color(255, 0, 0); pdf.cell(190, 10, normalize_for_pdf(f"Pasta grafikleri olusturulamadi: {e}"), ln=True); pdf.set_text_color(0, 0, 0)
        
    # --- Sayfa 4: Denklik Grafikleri (EK B) ---
    pdf.add_page()
    pdf.set_font("Arial", "B", 14)
    pdf.cell(190, 10, "EK B: Gorsel Denklik Kontrolu Grafikleri", ln=True)
    try:
        img_yas_box = pio.to_image(charts['fig_yas_box'], format="png"); img_hafta_box = pio.to_image(charts['fig_hafta_box'], format="png")
        img_egitim_bar = pio.to_image(charts['fig_egitim_bar'], format="png"); img_dogum_bar = pio.to_image(charts['fig_dogum_bar'], format="png")
        pdf.image(io.BytesIO(img_yas_box), w=90, h=70, x=10); pdf.image(io.BytesIO(img_hafta_box), w=90, h=70, x=110)
        pdf.ln(75); pdf.image(io.BytesIO(img_egitim_bar), w=90, h=70, x=10); pdf.image(io.BytesIO(img_dogum_bar), w=90, h=70, x=110)
    except Exception as e:
        pdf.set_text_color(255, 0, 0); pdf.cell(190, 10, normalize_for_pdf(f"Denklik grafikleri olusturulamadi: {e}"), ln=True); pdf.set_text_color(0, 0, 0)

    # --- Sayfa 5: Puan Evrimi ve Korelasyon Grafikleri (EK C) ---
    pdf.add_page()
    pdf.set_font("Arial", "B", 14)
    pdf.cell(190, 10, "EK C: Puan Evrimi ve Korelasyon Grafikleri", ln=True)
    try:
        img_vas_line = pio.to_image(charts['fig_vas_line'], format="png")
        img_stacked = pio.to_image(charts['fig_stacked'], format="png")
        img_heatmap = pio.to_image(charts['fig_heatmap'], format="png")
        pdf.image(io.BytesIO(img_vas_line), w=190, h=80); pdf.ln(85)
        pdf.image(io.BytesIO(img_stacked), w=190, h=90); pdf.ln(95)
        pdf.image(io.BytesIO(img_heatmap), w=190, h=100)
    except Exception as e:
        pdf.set_text_color(255, 0, 0); pdf.cell(190, 10, normalize_for_pdf(f"Puan evrimi/korelasyon grafikleri olusturulamadi: {e}"), ln=True); pdf.set_text_color(0, 0, 0)
        
    return bytes(pdf.output(dest='S'))

# --- 5. BACKEND: NÄ°HAÄ° Ä°STATÄ°STÄ°K MOTORU (HESAPLAMA) ---
def run_full_analysis(df_data):
    results = {} 
    
    missing_cols = [col for col in ALL_REQUIRED_COLUMNS if col not in df_data.columns]
    if missing_cols:
        return {'error': f"HATA: YÃ¼klediÄŸiniz Excel dosyasÄ± bir Åablon dosyasÄ± deÄŸil. Åu sÃ¼tunlar eksik: {', '.join(missing_cols)}. LÃ¼tfen 'BoÅŸ Excel Åablonunu Ä°ndir' butonunu kullanarak doÄŸru ÅŸablonu indirin ve verilerinizi oraya girin."}
    
    df_cleaned = df_data.copy()
    for col in NUMERIC_COLUMNS:
        df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')
        
    if df_cleaned[NUMERIC_COLUMNS].isnull().all().all():
        return {'error': "HATA: Analiz edilecek sayÄ±sal veri bulunamadÄ±. YÃ¼klediÄŸiniz Excel ÅŸablonundaki sayÄ±sal sÃ¼tunlar ('yas', 'korku_vas_baseline' vb.) tamamen boÅŸ veya geÃ§ersiz metin ('yok', 'N/A' vb.) iÃ§eriyor. LÃ¼tfen verilerinizi kontrol edin."}

    try:
        grup_mudahale = df_cleaned[df_cleaned['grup'] == 'MÃ¼dahale']
        grup_kontrol = df_cleaned[df_cleaned['grup'] == 'Kontrol']
    except KeyError:
        return {'error': "HATA: 'grup' sÃ¼tunu bulunamadÄ± veya 'MÃ¼dahale'/'Kontrol' deÄŸerleri yanlÄ±ÅŸ yazÄ±lmÄ±ÅŸ. LÃ¼tfen ÅŸablonu kontrol edin."}
    
    display_to_col_map_denklik = {
        'YaÅŸ': 'yas', 'Gebelik HaftasÄ±': 'gebelik_haftasi',
        'EÄŸitim Durumu': 'egitim_durumu', 'DoÄŸum BaÅŸlangÄ±cÄ± (DoÄŸum Åekli)': 'dogum_baslangici',
        'Medeni Durum': 'medeni_durum', 'Gelir DÃ¼zeyi': 'gelir_duzeyi',
        'Ã‡alÄ±ÅŸma Durumu': 'calisma_durumu', 'PlanlÄ± Gebelik': 'planli_gebelik_mi'
    }

    # --- FAZ 1 HESAPLAMALARI (Denklik) ---
    p_values_numeric = {
        'YaÅŸ': ttest_ind(grup_mudahale['yas'], grup_kontrol['yas'], equal_var=False, nan_policy='omit')[1],
        'Gebelik HaftasÄ±': ttest_ind(grup_mudahale['gebelik_haftasi'], grup_kontrol['gebelik_haftasi'], equal_var=False, nan_policy='omit')[1],
        'BaÅŸlangÄ±Ã§ Korku (VAS)': ttest_ind(grup_mudahale['korku_vas_baseline'], grup_kontrol['korku_vas_baseline'], equal_var=False, nan_policy='omit')[1],
        'BaÅŸlangÄ±Ã§ Korku (Ã–lÃ§ek)': ttest_ind(grup_mudahale['korku_olcek_baseline'], grup_kontrol['korku_olcek_baseline'], equal_var=False, nan_policy='omit')[1],
        'BaÅŸlangÄ±Ã§ EndiÅŸe (Oxford)': ttest_ind(grup_mudahale['endise_oxford_baseline'], grup_kontrol['endise_oxford_baseline'], equal_var=False, nan_policy='omit')[1]
    }
    p_values_categoric = {
        'EÄŸitim Durumu': chi2_contingency(pd.crosstab(df_cleaned['grup'], df_cleaned['egitim_durumu']))[1],
        'DoÄŸum BaÅŸlangÄ±cÄ± (DoÄŸum Åekli)': chi2_contingency(pd.crosstab(df_cleaned['grup'], df_cleaned['dogum_baslangici']))[1],
        'Medeni Durum': chi2_contingency(pd.crosstab(df_cleaned['grup'], df_cleaned['medeni_durum']))[1],
        'Gelir DÃ¼zeyi': chi2_contingency(pd.crosstab(df_cleaned['grup'], df_cleaned['gelir_duzeyi']))[1],
        'Ã‡alÄ±ÅŸma Durumu': chi2_contingency(pd.crosstab(df_cleaned['grup'], df_cleaned['calisma_durumu']))[1],
        'PlanlÄ± Gebelik': chi2_contingency(pd.crosstab(df_cleaned['grup'], df_cleaned['planli_gebelik_mi']))[1]
    }
    results['faz1_numeric_p_values'] = p_values_numeric
    results['faz1_categoric_p_values'] = p_values_categoric
    
    all_p_values_dict = {**p_values_numeric, **p_values_categoric}
    failed_vars_display_names = [var_name for var_name, p in all_p_values_dict.items() if p < 0.05]
    results['faz1_is_denk'] = len(failed_vars_display_names) == 0
    results['faz1_failed_vars_display_names'] = failed_vars_display_names 
    
    # --- DÄ°NAMÄ°K DÃœZELTME MOTORU ---
    correction_formula_part = ""
    if not results['faz1_is_denk']:
        for var_name in failed_vars_display_names:
            col_name = display_to_col_map_denklik.get(var_name)
            if col_name: 
                if col_name in CATEGORIC_COLUMNS:
                    correction_formula_part += f" + C({col_name})"
                else:
                    correction_formula_part += f" + {col_name}"
    results['correction_applied'] = correction_formula_part 
    
    # --- FAZ 2 HESAPLAMALARI (Dinamik FormÃ¼llerle) ---
    f_h1_vas_base = 'korku_vas_4cm ~ grup + korku_vas_baseline'
    f_h1_olcek_base = 'korku_olcek_4cm ~ grup + korku_olcek_baseline'
    f_h2_vas_base = 'korku_vas_8cm ~ grup + korku_vas_4cm'
    f_h2_olcek_base = 'korku_olcek_8cm ~ grup + korku_olcek_4cm'
    f_h3_oxford_base = 'endise_oxford_son_test ~ grup + endise_oxford_baseline'
    
    results['h1_vas_p'] = sm.stats.anova_lm(ols(f_h1_vas_base + correction_formula_part, data=df_cleaned.dropna(subset=['korku_vas_4cm', 'grup', 'korku_vas_baseline'])).fit(), typ=3).loc['grup', 'PR(>F)']
    results['h1_olcek_p'] = sm.stats.anova_lm(ols(f_h1_olcek_base + correction_formula_part, data=df_cleaned.dropna(subset=['korku_olcek_4cm', 'grup', 'korku_olcek_baseline'])).fit(), typ=3).loc['grup', 'PR(>F)']
    results['h2_vas_p'] = sm.stats.anova_lm(ols(f_h2_vas_base + correction_formula_part, data=df_cleaned.dropna(subset=['korku_vas_8cm', 'grup', 'korku_vas_4cm'])).fit(), typ=3).loc['grup', 'PR(>F)']
    results['h2_olcek_p'] = sm.stats.anova_lm(ols(f_h2_olcek_base + correction_formula_part, data=df_cleaned.dropna(subset=['korku_olcek_8cm', 'grup', 'korku_olcek_4cm'])).fit(), typ=3).loc['grup', 'PR(>F)']
    results['h3_oxford_p'] = sm.stats.anova_lm(ols(f_h3_oxford_base + correction_formula_part, data=df_cleaned.dropna(subset=['endise_oxford_son_test', 'grup', 'endise_oxford_baseline'])).fit(), typ=3).loc['grup', 'PR(>F)']
    
    # --- AkÄ±llÄ± Yorum v2.0 (Nihai Yorum Metnini OluÅŸtur) ---
    h_p_values = [results['h1_vas_p'], results['h1_olcek_p'], results['h2_vas_p'], results['h2_olcek_p'], results['h3_oxford_p']]
    faz2_basarili = any(p < 0.05 for p in h_p_values)
    
    final_report_text = ""
    if results['faz1_is_denk'] and faz2_basarili:
        results['final_report_title'] = "NÄ°HAÄ° SONUÃ‡: GÃ¼Ã§lÃ¼ Bulgular (Pozitif)"
        final_report_text = "Yorum: AraÅŸtÄ±rma, gruplar arasÄ±nda tam denklik (FAZ 1) saÄŸlamÄ±ÅŸtÄ±r. Ä°statistiksel analizler (FAZ 2), mÃ¼dahale grubunda korku ve/veya endiÅŸe dÃ¼zeylerinde anlamlÄ± bir azalma olduÄŸunu doÄŸrulamÄ±ÅŸtÄ±r. Bu bulgular, nefes egzersizi mÃ¼dahalesinin, protokolde hedeflenen baÄŸÄ±mlÄ± deÄŸiÅŸkenler Ã¼zerinde anlamlÄ± ve pozitif bir etkiye sahip olduÄŸunu gÃ¼Ã§lÃ¼ bir ÅŸekilde desteklemektedir."
    elif not results['faz1_is_denk'] and faz2_basarili:
        results['final_report_title'] = "NÄ°HAÄ° SONUÃ‡: DÃ¼zeltilmiÅŸ Bulgular (Pozitif)"
        failed_vars_str = ", ".join(results['faz1_failed_vars_display_names'])
        final_report_text = f"Yorum: Hipotezler (FAZ 2) mÃ¼dahale lehine Ã§Ä±ksa da, FAZ 1 denklik testlerinde ({failed_vars_str}) baÅŸarÄ±sÄ±zlÄ±k tespit edilmiÅŸtir. Bu 'karÄ±ÅŸtÄ±rÄ±cÄ± deÄŸiÅŸkenler', FAZ 2 ANCOVA analizine otomatik olarak eklenerek etkileri 'kontrol altÄ±na alÄ±nmÄ±ÅŸtÄ±r'. DÃ¼zeltilmiÅŸ sonuÃ§lar, mÃ¼dahalenin (denklik hatalarÄ±na raÄŸmen) pozitif bir etkiye sahip olduÄŸunu desteklemektedir."
    elif results['faz1_is_denk'] and not faz2_basarili:
        results['final_report_title'] = "NÄ°HAÄ° SONUÃ‡: Etkisiz MÃ¼dahale (NÃ¶tr Bulgular)"
        final_report_text = "Yorum: AraÅŸtÄ±rma, gruplar arasÄ±nda tam denklik (FAZ 1) saÄŸlamÄ±ÅŸ olmasÄ±na raÄŸmen, hipotez testleri (FAZ 2) mÃ¼dahalenin istatistiksel olarak anlamlÄ± bir fark yaratmadÄ±ÄŸÄ±nÄ± (p > 0.05) gÃ¶stermiÅŸtir. Bu bulgular, nefes egzersizi mÃ¼dahalesinin, bu Ã§alÄ±ÅŸmanÄ±n koÅŸullarÄ± ve Ã¶rneklemi Ã¼zerinde Ã¶lÃ§Ã¼lebilir bir etkiye sahip olmadÄ±ÄŸÄ±nÄ± gÃ¶stermektedir."
    else: # not faz1_is_denk and not faz2_basarili
        results['final_report_title'] = "NÄ°HAÄ° SONUÃ‡: SonuÃ§suz Bulgular (GeÃ§ersiz)"
        final_report_text = "Yorum: AraÅŸtÄ±rma hem FAZ 1 denklik testlerinde baÅŸarÄ±sÄ±z olmuÅŸ hem de FAZ 2 hipotez testlerinde anlamlÄ± bir sonuÃ§ Ã¼retememiÅŸtir. Gruplar arasÄ±ndaki baÅŸlangÄ±Ã§ farklarÄ± ve mÃ¼dahalenin etkisizliÄŸi nedeniyle, araÅŸtÄ±rma sonuÃ§larÄ± 'geÃ§ersiz' (inconclusive) kabul edilmelidir."
    
    results['final_report_text'] = final_report_text.strip()
    results['error'] = None
    return results

# --- 6. BACKEND: TÃœM GÃ–RSELLERÄ° OLUÅTURMA MOTORU ---
def generate_all_charts(df_charts):
    charts = {}
    
    df_charts_norm = df_charts.copy()
    for col in CATEGORIC_COLUMNS:
        df_charts_norm[col] = df_charts_norm[col].astype(str).apply(normalize_for_pdf)

    # --- BÃ–LÃœM 1: Frekans TablolarÄ± & Pasta Grafikler ---
    df_pie = df_charts_norm['medeni_durum'].value_counts().reset_index()
    charts['fig_pie_medeni'] = px.pie(df_pie, names='medeni_durum', values='count', hole=0.3, title=normalize_for_pdf("Medeni Durum"))
    charts['fig_pie_medeni'].update_traces(textposition='inside', textinfo='percent+label')
    charts['fig_pie_medeni'].update_layout(showlegend=False, margin=dict(t=30, b=20, l=20, r=20))

    df_pie = df_charts_norm['gelir_duzeyi'].value_counts().reset_index()
    charts['fig_pie_gelir'] = px.pie(df_pie, names='gelir_duzeyi', values='count', hole=0.3, title=normalize_for_pdf("Gelir DÃ¼zeyi"),
                                    category_orders={'gelir_duzeyi': ['Dusuk', 'Orta', 'Yuksek']})
    charts['fig_pie_gelir'].update_traces(textposition='inside', textinfo='percent+label')
    charts['fig_pie_gelir'].update_layout(showlegend=False, margin=dict(t=30, b=20, l=20, r=20))

    df_pie = df_charts_norm['calisma_durumu'].value_counts().reset_index()
    charts['fig_pie_calisma'] = px.pie(df_pie, names='calisma_durumu', values='count', hole=0.3, title=normalize_for_pdf("Ã‡alÄ±ÅŸma Durumu"))
    charts['fig_pie_calisma'].update_traces(textposition='inside', textinfo='percent+label')
    charts['fig_pie_calisma'].update_layout(showlegend=False, margin=dict(t=30, b=20, l=20, r=20))

    df_pie = df_charts_norm['planli_gebelik_mi'].value_counts().reset_index()
    charts['fig_pie_plan'] = px.pie(df_pie, names='planli_gebelik_mi', values='count', hole=0.3, title=normalize_for_pdf("PlanlÄ± Gebelik"))
    charts['fig_pie_plan'].update_traces(textposition='inside', textinfo='percent+label')
    charts['fig_pie_plan'].update_layout(showlegend=False, margin=dict(t=30, b=20, l=20, r=20))
    
    # --- BÃ–LÃœM 2: SayÄ±sal Denklik (Kutu Grafikleri) ---
    charts['fig_yas_box'] = px.box(df_charts_norm, x='grup', y='yas', color='grup', title=normalize_for_pdf('YaÅŸ DaÄŸÄ±lÄ±mÄ± (Gruplara GÃ¶re)'), points="all")
    charts['fig_yas_box'].update_layout(showlegend=False)
    
    charts['fig_hafta_box'] = px.box(df_charts_norm, x='grup', y='gebelik_haftasi', color='grup', title=normalize_for_pdf('Gebelik HaftasÄ± DaÄŸÄ±lÄ±mÄ± (Gruplara GÃ¶re)'), points="all")
    charts['fig_hafta_box'].update_layout(showlegend=False)

    # --- BÃ–LÃœM 3: Kategorik Denklik (SÃ¼tun Grafikleri) ---
    charts['fig_egitim_bar'] = px.histogram(df_charts_norm, x='egitim_durumu', color='grup', barmode='group', title=normalize_for_pdf('EÄŸitim Durumu (Gruplara GÃ¶re)'),
                                            category_orders={'egitim_durumu': ['Ilkokul', 'Lise', 'Universite']})
    
    charts['fig_dogum_bar'] = px.histogram(df_charts_norm, x='dogum_baslangici', color='grup', barmode='group', title=normalize_for_pdf('DoÄŸum BaÅŸlangÄ±cÄ± (Gruplara GÃ¶re)'))
    
    # --- BÃ–LÃœM 4: Ortalama Puan Evrimi (Ã‡izgi Grafikler) ---
    df_mean = df_charts_norm.groupby('grup')[['korku_vas_baseline', 'korku_vas_4cm', 'korku_vas_8cm']].mean().reset_index()
    zaman_etiketleri_vas = {'korku_vas_baseline': 'Baseline', 'korku_vas_4cm': '4cm', 'korku_vas_8cm': '8cm'}
    df_vas_long = df_mean.melt(id_vars='grup', value_vars=zaman_etiketleri_vas.keys(), var_name='Zaman', value_name='Ortalama Puan (VAS)')
    df_vas_long['Zaman'] = df_vas_long['Zaman'].map(zaman_etiketleri_vas)
    charts['fig_vas_line'] = px.line(df_vas_long, x='Zaman', y='Ortalama Puan (VAS)', color='grup', title=normalize_for_pdf('Ortalama VAS (Korku) PuanÄ± Evrimi'), markers=True,
                                     category_orders={'Zaman': ['Baseline', '4cm', '8cm']})

    # --- BÃ–LÃœM 5: Likert-tipi GÃ¶rselleÅŸtirme ---
    vas_bins = [0, 4, 7, 10.1]; vas_labels = [normalize_for_pdf('DÃ¼ÅŸÃ¼k Korku (0-3)'), normalize_for_pdf('Orta Korku (4-6)'), normalize_for_pdf('YÃ¼ksek Korku (7-10)')]
    df_likert = df_charts_norm[['grup', 'korku_vas_baseline', 'korku_vas_4cm', 'korku_vas_8cm']].copy()
    df_likert['Baseline'] = pd.cut(df_likert['korku_vas_baseline'], bins=vas_bins, labels=vas_labels, right=False)
    df_likert['4cm (Latent Son)'] = pd.cut(df_likert['korku_vas_4cm'], bins=vas_bins, labels=vas_labels, right=False)
    df_likert['8cm (Aktif Son)'] = pd.cut(df_likert['korku_vas_8cm'], bins=vas_bins, labels=vas_labels, right=False)
    df_long = df_likert.melt(id_vars=['grup'], value_vars=['Baseline', '4cm (Latent Son)', '8cm (Aktif Son)'], var_name='Olum Zamani', value_name='Korku Seviyesi')
    color_map = {vas_labels[0]: 'green', vas_labels[1]: 'orange', vas_labels[2]: 'red'}
    charts['fig_stacked'] = px.histogram(df_long, x='Olum Zamani', color='Korku Seviyesi', facet_col='grup', barmode='stack', barnorm='percent', title=normalize_for_pdf('Korku Seviyelerinin (VAS) Zamana GÃ¶re DeÄŸiÅŸimi'),
                                         color_discrete_map=color_map, category_orders={"Olum Zamani": ['Baseline', '4cm (Latent Son)', '8cm (Aktif Son)'], "Korku Seviyesi": vas_labels}) 

    # --- BÃ–LÃœM 6: Korelasyon IsÄ± HaritasÄ± ---
    corr_cols_in_df = [col for col in NUMERIC_COLUMNS if col in df_charts_norm.columns]
    corr_matrix = df_charts_norm[corr_cols_in_df].corr()
    charts['fig_heatmap'] = px.imshow(corr_matrix, text_auto='.2f', aspect="auto", color_continuous_scale='RdBu_r', zmin=-1, zmax=1, title=normalize_for_pdf("SayÄ±sal DeÄŸiÅŸkenler Korelasyon IsÄ± HaritasÄ±"))
    
    return charts

# --- 7. FRONTEND: TÃœM ARAYÃœZ FONKSÄ°YONLARI ---

def display_kÄ±lavuz_tab():
    """ (v12.2) KÄ±lavuz sekmesini (iÃ§i dolu metinlerle) Ã§izer."""
    st.header("Protokol KÄ±lavuzu ve Metodoloji")
    st.markdown("Bu bÃ¶lÃ¼mde, analiz motorunun dayandÄ±ÄŸÄ± istatistiksel yÃ¶ntemler ve veri setindeki deÄŸiÅŸkenlerin rolleri profesyonel bir dille aÃ§Ä±klanmaktadÄ±r.")
    
    st.subheader("1. Temel Metodolojik Terimler")
    st.markdown("""
    - **Visual Analog Skala (VAS):** KatÄ±lÄ±mcÄ±nÄ±n; aÄŸrÄ±, korku veya anksiyete gibi sÃ¼bjektif bir deneyimi, 0 (hiÃ§ yok) ile 10 (en ÅŸiddetli) arasÄ±nda derecelendirdiÄŸi, valide edilmiÅŸ (geÃ§erliliÄŸi kanÄ±tlanmÄ±ÅŸ) bir Ã¶lÃ§Ã¼m aracÄ±dÄ±r.
    - **Latent Faz:** DoÄŸum eyleminin baÅŸladÄ±ÄŸÄ±, servikal silinme ve dilatasyonun (aÃ§Ä±lma) baÅŸladÄ±ÄŸÄ± ancak ilerlemenin yavaÅŸ olduÄŸu (protokolde ~0-4 cm arasÄ± olarak tanÄ±mlanan) evredir.
    - **Aktif Faz:** Servikal dilatasyonun hÄ±zlandÄ±ÄŸÄ± (protokolde ~4-8/10 cm arasÄ± olarak tanÄ±mlanan), doÄŸum eyleminin gÃ¼Ã§lÃ¼ ve dÃ¼zenli kasÄ±lmalarla ilerlediÄŸi evredir.
    """)
    
    st.subheader("2. FAZ 1: GruplarÄ±n BaÅŸlangÄ±Ã§ DenkliÄŸi (Baseline Equivalence)")
    st.info("AmaÃ§: AraÅŸtÄ±rmanÄ±n iÃ§ geÃ§erliliÄŸini (internal validity) saÄŸlamak.")
    st.markdown("""
    Randomize KontrollÃ¼ Deneylerde (RCT), 'MÃ¼dahale' (Deney) ve 'Kontrol' gruplarÄ± oluÅŸturulur. Bu iki grubun, araÅŸtÄ±rma baÅŸlamadan Ã¶nceki **karÄ±ÅŸtÄ±rÄ±cÄ± deÄŸiÅŸkenler (confounders)** bakÄ±mÄ±ndan birbirine denk olmasÄ± hayati Ã¶nem taÅŸÄ±r.
    
    **Denklik Testi (FAZ 1)**, tam olarak bu kontrolÃ¼ yapar. Raporumuzda, denklik deÄŸiÅŸkenleri iÃ§in `p > 0.05` (p-deÄŸerinin 0.05'ten bÃ¼yÃ¼k) olmasÄ±, "gruplar arasÄ±nda istatistiksel olarak anlamlÄ± bir fark yoktur" anlamÄ±na gelir. Bu, randomizasyonun baÅŸarÄ±lÄ± olduÄŸunu ve gruplarÄ±n karÅŸÄ±laÅŸtÄ±rmaya uygun (homojen) olduÄŸunu teyit eder.
    """)
    
    st.subheader("3. FAZ 2: Hipotez Testleri iÃ§in ANCOVA'nÄ±n RolÃ¼")
    st.info("AmaÃ§: MÃ¼dahalenin 'saf' etkisini (net effect) izole etmek.")
    st.markdown("""
    Hipotezleri test ederken (Ã¶rn. 8cm'deki korku puanlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±rken) basit bir t-testi kullanmak, katÄ±lÄ±mcÄ±larÄ±n 4cm'deki bireysel farklÄ±lÄ±klarÄ±nÄ± gÃ¶z ardÄ± edecektir.
    
    **ANCOVA (Kovaryans Analizi)**, Son-Test (Post-Test) puanlarÄ±nÄ± (Ã¶rn. `korku_vas_8cm`) gruplar arasÄ±nda karÅŸÄ±laÅŸtÄ±rÄ±rken, katÄ±lÄ±mcÄ±larÄ±n Ã–n-Test (Pre-Test) puanlarÄ±nÄ± (Ã¶rn. `korku_vas_4cm`) bir **'kovaryant' (kontrol deÄŸiÅŸkeni)** olarak analize dahil eder.
    
    **Bu motor (v12.2) daha da akÄ±llÄ±dÄ±r:** EÄŸer FAZ 1'de 'YaÅŸ' veya 'EÄŸitim Durumu' gibi bir deÄŸiÅŸkende denklik bozulursa (p < 0.05), bu 'sorunlu' deÄŸiÅŸkenleri de ANCOVA formÃ¼lÃ¼ne otomatik olarak bir kovaryant olarak ekler ve sonucu buna gÃ¶re **DÃœZELTÄ°R**.
    """)
    
    st.divider()
    st.subheader("4. Veri Seti DeÄŸiÅŸkenlerinin (SÃ¼tunlarÄ±n) Analizdeki RolÃ¼")
    
    st.markdown("Veri setindeki her sÃ¼tun, analizde belirli bir rol Ã¼stlenir. Bu roller 3 ana kategoriye ayrÄ±lÄ±r (Ä°ndireceÄŸiniz Excel Åablonundaki sÃ¼tun adlarÄ±dÄ±r):")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.info("Grup A: Denklik DeÄŸiÅŸkenleri (KarÄ±ÅŸtÄ±rÄ±cÄ±lar)")
        st.markdown("""
        "FAZ 1: Denklik Testi" iÃ§in kullanÄ±lÄ±rlar. GruplarÄ±n homojenliÄŸini (benzerliÄŸini) test ederler.
        - **`yas`** - **`gebelik_haftasi`** - **`egitim_durumu`**
        - **`dogum_baslangici`** - **`medeni_durum`** - **`gelir_duzeyi`**
        - **`calisma_durumu`** - **`planli_gebelik_mi`**
        """)
    with col2:
        st.info("Grup B: Kovaryantlar (Ã–n-Testler)")
        st.markdown("""
        "FAZ 2: ANCOVA" analizinde 'kontrol deÄŸiÅŸkeni' olarak kullanÄ±lÄ±rlar.
        - **`korku_vas_baseline`** - **`korku_olcek_baseline`**
        - **`endise_oxford_baseline`**
        - **`korku_vas_4cm`** - **`korku_olcek_4cm`**
        """)
    with col3:
        st.info("Grup C: BaÄŸÄ±mlÄ± DeÄŸiÅŸkenler (Son-Testler)")
        st.markdown("""
        Bunlar, mÃ¼dahalenin etkisinin Ã¶lÃ§Ã¼ldÃ¼ÄŸÃ¼ nihai 'sonuÃ§' deÄŸiÅŸkenleridir.
        - **`korku_vas_4cm`** - **`korku_olcek_4cm`**
        - **`korku_vas_8cm`** - **`korku_olcek_8cm`**
        - **`endise_oxford_son_test`**
        """)

def display_dashboard_tab(df_charts, charts):
    """(v12.0) Dashboard sekmesini, Ã¶nceden oluÅŸturulmuÅŸ grafiklerle Ã§izer."""
    st.header("Veri Seti Ã–zeti (KeÅŸifsel Veri Analizi Dashboard)")
    try:
        st.subheader("Sosyodemografik DaÄŸÄ±lÄ±mlar (Frekans ve YÃ¼zdeler)")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Medeni Durum**")
            st.plotly_chart(charts['fig_pie_medeni'], use_container_width=True)
            df_pie_data = df_charts['medeni_durum'].value_counts().reset_index().rename(columns={'medeni_durum': 'Kategori', 'count': 'SayÄ± (n)'})
            st.dataframe(df_pie_data, use_container_width=True)
        with col2:
            st.markdown("**Gelir DÃ¼zeyi**")
            st.plotly_chart(charts['fig_pie_gelir'], use_container_width=True)
            df_pie_data = df_charts['gelir_duzeyi'].value_counts().reset_index().rename(columns={'gelir_duzeyi': 'Kategori', 'count': 'SayÄ± (n)'})
            st.dataframe(df_pie_data, use_container_width=True)
        
        st.divider()
        col3, col4 = st.columns(2)
        with col3:
            st.markdown("**Ã‡alÄ±ÅŸma Durumu**")
            st.plotly_chart(charts['fig_pie_calisma'], use_container_width=True)
            df_pie_data = df_charts['calisma_durumu'].value_counts().reset_index().rename(columns={'calisma_durumu': 'Kategori', 'count': 'SayÄ± (n)'})
            st.dataframe(df_pie_data, use_container_width=True)
        with col4:
            st.markdown("**PlanlÄ± Gebelik**")
            st.plotly_chart(charts['fig_pie_plan'], use_container_width=True)
            df_pie_data = df_charts['planli_gebelik_mi'].value_counts().reset_index().rename(columns={'planli_gebelik_mi': 'Kategori', 'count': 'SayÄ± (n)'})
            st.dataframe(df_pie_data, use_container_width=True)
        
        st.divider()
        st.subheader("SayÄ±sal DeÄŸiÅŸkenlerin Gruplara GÃ¶re DaÄŸÄ±lÄ±mÄ± (Denklik KontrolÃ¼)")
        col1_box, col2_box = st.columns(2)
        with col1_box:
            st.plotly_chart(charts['fig_yas_box'], use_container_width=True)
        with col2_box:
            st.plotly_chart(charts['fig_hafta_box'], use_container_width=True)
        
        st.divider()
        st.subheader("Kategorik DeÄŸiÅŸkenlerin Gruplara GÃ¶re DaÄŸÄ±lÄ±mÄ± (Denklik KontrolÃ¼)")
        col1_bar, col2_bar = st.columns(2)
        with col1_bar:
            st.plotly_chart(charts['fig_egitim_bar'], use_container_width=True)
        with col2_bar:
            st.plotly_chart(charts['fig_dogum_bar'], use_container_width=True)
            
        st.divider()
        st.subheader("Ortalama PuanlarÄ±n Zamana GÃ¶re Evrimi")
        st.plotly_chart(charts['fig_vas_line'], use_container_width=True)
        
        st.divider()
        st.subheader("Korku Seviyesi DaÄŸÄ±lÄ±mÄ±nÄ±n Evrimi (Likert-tipi)")
        st.plotly_chart(charts['fig_stacked'], use_container_width=True)
        
        st.divider()
        st.subheader("DeÄŸiÅŸken Ä°liÅŸki HaritasÄ± (Korelasyon)")
        st.plotly_chart(charts['fig_heatmap'], use_container_width=True)
        
    except Exception as e:
        st.error(f"GÃ¶rselleÅŸtirme hatasÄ±: {e}. LÃ¼tfen Excel dosyanÄ±zdaki sÃ¼tun adlarÄ±nÄ± ('KÄ±lavuz' sekmesinde belirtilen) kontrol edin.")

def display_analysis_tab(analysis_results, charts_for_pdf):
    """(v12.0) Analiz sekmesini Ã§izer ve PDF indirme butonunu yÃ¶netir."""
    try:
        if analysis_results.get('error'):
            st.error(analysis_results['error'])
        else:
            st.divider()
            st.header("FAZ 1: BaÅŸlangÄ±Ã§ DenkliÄŸi (TanÄ±mlayÄ±cÄ± Ä°statistikler)")
            df_numeric = pd.DataFrame(analysis_results['faz1_numeric_p_values'].items(), columns=["DeÄŸiÅŸken", "p-deÄŸeri"])
            df_categoric = pd.DataFrame(analysis_results['faz1_categoric_p_values'].items(), columns=["DeÄŸiÅŸken", "p-deÄŸeri"])
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("SayÄ±sal DeÄŸiÅŸkenler")
                st.dataframe(df_numeric, use_container_width=True)
            with col2:
                st.subheader("Kategorik DeÄŸiÅŸkenler")
                st.dataframe(df_categoric, use_container_width=True) 
            
            if analysis_results['faz1_is_denk']:
                st.success("SONUÃ‡: Randomizasyon BAÅARILI (TÃ¼m p > 0.05)")
                st.markdown("Gruplar arasÄ±nda istatistiksel olarak anlamlÄ± bir baÅŸlangÄ±Ã§ farkÄ± bulunamamÄ±ÅŸtÄ±r. Bu, gruplarÄ±n homojen (denk) olduÄŸunu ve araÅŸtÄ±rmanÄ±n iÃ§ geÃ§erliliÄŸinin yÃ¼ksek olduÄŸunu gÃ¶sterir.")
            else:
                st.warning("SONUÃ‡: Randomizasyon BAÅARISIZ (p < 0.05)")
                failed_vars_str = ", ".join(analysis_results['faz1_failed_vars_display_names'])
                st.markdown(f"**Neden KaynaklÄ±?:** Analiz, gruplar arasÄ±nda **{failed_vars_str}** deÄŸiÅŸken(ler)i aÃ§Ä±sÄ±ndan istatistiksel olarak anlamlÄ± bir fark (p < 0.05) tespit etmiÅŸtir.")
            
            st.divider()
            st.header("FAZ 2: Hipotez Testleri (ANCOVA)")
            correction_text = analysis_results.get('correction_applied')
            if correction_text:
                st.info(f"""
                    **DÄ°KKAT: Ä°STATÄ°STÄ°KSEL DÃœZELTME UYGULANDI**\n
                    FAZ 1'deki denklik hatasÄ±(larÄ±) nedeniyle, FAZ 2 ANCOVA formÃ¼llerine 
                    ÅŸu deÄŸiÅŸken(ler) 'kontrol deÄŸiÅŸkeni' (kovaryant) olarak 
                    otomatik eklenmiÅŸtir: **{correction_text}**\n
                    GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z p-deÄŸerleri, bu 'dÃ¼zeltilmiÅŸ' sonuÃ§lardÄ±r.
                """)
            
            col_h1, col_h2, col_h3 = st.columns(3)
            with col_h1:
                st.subheader("[H1: Latent Faz Korku]")
                p1_vas = analysis_results['h1_vas_p']; p1_olcek = analysis_results['h1_olcek_p']
                st.metric(label="VAS Sonucu", value="DESTEKLENDÄ°" if p1_vas < 0.05 else "Reddedildi", delta=f"p-deÄŸeri: {p1_vas:.6f}")
                st.metric(label="DoÄŸum Korku Ã–lÃ§eÄŸi Sonucu", value="DESTEKLENDÄ°" if p1_olcek < 0.05 else "Reddedildi", delta=f"p-deÄŸeri: {p1_olcek:.6f}")
            with col_h2:
                st.subheader("[H2: Aktif Faz Korku]")
                p2_vas = analysis_results['h2_vas_p']; p2_olcek = analysis_results['h2_olcek_p']
                st.metric(label="VAS Sonucu", value="DESTEKLENDÄ°" if p2_vas < 0.05 else "Reddedildi", delta=f"p-deÄŸeri: {p2_vas:.6f}")
                st.metric(label="DoÄŸum Korku Ã–lÃ§eÄŸi Sonucu", value="DESTEKLENDÄ°" if p2_olcek < 0.05 else "Reddedildi", delta=f"p-deÄŸeri: {p2_olcek:.6f}")
            with col_h3:
                st.subheader("[H3: EndiÅŸe DÃ¼zeyi]")
                p3_oxford = analysis_results['h3_oxford_p']
                st.metric(label="Oxford EndiÅŸe Ã–lÃ§eÄŸi Sonucu", value="DESTEKLENDÄ°" if p3_oxford < 0.05 else "Reddedildi", delta=f"p-deÄŸeri: {p3_oxford:.6f}")
            
            st.divider()
            st.header("Nihai Rapor Yorumu (Analist Ã–zeti)")
            report_title = analysis_results['final_report_title']
            report_text = analysis_results['final_report_text']
            if "GÃ¼Ã§lÃ¼" in report_title: st.success(report_title)
            elif "DÃ¼zeltilmiÅŸ" in report_title: st.success(report_title) 
            elif "Etkisiz" in report_title: st.info(report_title)
            else: st.error(report_title)
            st.markdown(report_text)
            
            st.balloons()
            st.divider()
            
            st.header("Raporu DÄ±ÅŸa Aktar")
            try:
                # (v12.0) PDF BUTONU ARTIK GRAFÄ°KLERÄ° DE GÃ–NDERÄ°YOR
                pdf_bytes = create_pdf_report(analysis_results, charts_for_pdf)
                st.download_button(
                    label="KapsamlÄ± Raporu PDF Olarak Ä°ndir (Metin + Grafikler)",
                    data=pdf_bytes,
                    file_name="Ebelik_Arastirma_Raporu_v12.pdf",
                    mime="application/pdf",
                    use_container_width=True
                )
            except Exception as pdf_e:
                st.error(f"PDF oluÅŸturulurken bir hata oluÅŸtu: {pdf_e}")
                st.error("Rapor PDF'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lemedi. 'kaleido' kÃ¼tÃ¼phanesinin kurulu olduÄŸundan emin olun.")
            
    except Exception as e:
        st.error(f"Genel bir hata oluÅŸtu: {e}")
        st.warning("Analiz baÅŸarÄ±sÄ±z olduÄŸu iÃ§in PDF raporu oluÅŸturulamaz.")

def clear_session_state():
    """Yeni bir dosya yÃ¼klendiÄŸinde eski sonuÃ§larÄ± ve grafikleri hafÄ±zadan siler."""
    keys_to_delete = ['analysis_results', 'df_for_tabs', 'charts_dict']
    for key in keys_to_delete:
        if key in st.session_state:
            del st.session_state[key]

# --- 8. ANA UYGULAMA MANTIÄI (v12.2) ---

st.set_page_config(page_title="Ebelik AraÅŸtÄ±rmasÄ± Analiz Motoru", layout="wide")

# --- Kenar Ã‡ubuÄŸu (Sidebar) ---
st.sidebar.title("ğŸ¤° Ebelik AraÅŸtÄ±rmasÄ±")
st.sidebar.header("AdÄ±m 1: Åablonu Ä°ndirin")
excel_buffer = create_template_excel()
st.sidebar.download_button(
    label="BoÅŸ Excel Åablonunu Ä°ndir",
    data=excel_buffer,
    file_name="Ebelik_Veri_Giris_Sabloni.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    use_container_width=True,
    help="Analiz motorunun Ã§alÄ±ÅŸmasÄ± iÃ§in verilerinizi bu ÅŸablona girmeniz gerekmektedir."
)

st.sidebar.header("AdÄ±m 2: Åablonu YÃ¼kleyin")
uploaded_file = st.sidebar.file_uploader(
    "LÃ¼tfen doldurduÄŸunuz ÅŸablonu buraya yÃ¼kleyin",
    type=["xlsx"],
    on_change=clear_session_state, 
    help="Verilerinizle doldurduÄŸunuz 'Ebelik_Veri_Giris_Sabloni.xlsx' dosyasÄ±nÄ± yÃ¼kleyin."
)

st.sidebar.header("AdÄ±m 3: Analiz Edin")
start_analysis = st.sidebar.button("Analizi BaÅŸlat", type="primary", use_container_width=True, help="YÃ¼klenen veriyi analiz eder ve raporlar.")
st.sidebar.divider()
st.sidebar.info("v12.2 - Uzman Sistem (Temiz & KapsamlÄ± Rapor)")

# --- Ana ArayÃ¼z ---
st.title("Ebelik AraÅŸtÄ±rmasÄ± Ä°statistiksel Analiz Raporu")

# --- v12.3 Eklentisi: Footer ---
footer_html = """
<style>
.footer {
    position: fixed;
    right: 15px; /* Kenardan biraz boÅŸluk */
    bottom: 10px;
    width: auto;
    text-align: right;
    font-size: 12px;
    color: #888; /* DÃ¼ÅŸÃ¼k gÃ¶rÃ¼nÃ¼rlÃ¼klÃ¼ gri */
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
}
.footer a {
    color: #0077B5; /* LinkedIn mavisine yakÄ±n bir renk */
    text-decoration: none; /* Alt Ã§izgiyi kaldÄ±r */
}
.footer a:hover {
    text-decoration: underline; /* Ãœzerine gelince altÄ±nÄ± Ã§iz */
}
</style>

<div class="footer">
    GeliÅŸtirici: OÄŸuzhan YazÄ±cÄ±<br>
    Â© 2025 TÃ¼m haklarÄ± saklÄ±dÄ±r. | 
    <a href="https://www.linkedin.com/in/o%C4%9Fuzhan-yaz%C4%B1c%C4%B1-2b09aa327/" target="_blank">LinkedIn Profilim</a>
</div>
"""
st.markdown(footer_html, unsafe_allow_html=True)
# --- Footer Eklentisi BitiÅŸi ---


# 3 Sekmeyi her zaman gÃ¶ster
tab_kÄ±lavuz, tab_dashboard, tab_analiz = st.tabs([
    "â„¹ï¸ Protokol KÄ±lavuzu", 
    "ğŸ“Š Veri Seti Ã–zeti (Dashboard)",
    "ğŸ“ˆ Ä°statistiksel Analiz (Rapor)"
])

with tab_kÄ±lavuz:
    display_kÄ±lavuz_tab()

# --- Analiz ve YÃ¼kleme MantÄ±ÄŸÄ± ---
if start_analysis:
    if uploaded_file is not None:
        if 'analysis_results' not in st.session_state: 
            try:
                df_from_excel = None
                with st.spinner("Veri okunuyor ve 'yok', '7,0' gibi hatalÄ± giriÅŸler temizleniyor..."):
                    df_from_excel = pd.read_excel(uploaded_file, engine='openpyxl')
                    
                    df_cleaned = df_from_excel.copy()
                    for col in NUMERIC_COLUMNS:
                        if col in df_cleaned.columns:
                            df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')
                        else:
                            pass 
                    
                    st.session_state.df_for_tabs = df_cleaned 

                with st.spinner("Ä°statistiksel analiz motoru Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor... (Dinamik DÃ¼zeltme yapÄ±lÄ±yor...)"):
                    st.session_state.analysis_results = run_full_analysis(df_cleaned)
                
                if st.session_state.analysis_results.get('error') is None:
                    with st.spinner("TÃ¼m dashboard grafikleri oluÅŸturuluyor... (Bu iÅŸlem 10-15 saniye sÃ¼rebilir...)"):
                        st.session_state.charts_dict = generate_all_charts(df_cleaned)
                else:
                    st.session_state.charts_dict = {} 
                
                st.rerun() 
                
            except Exception as e:
                st.error(f"Genel bir hata oluÅŸtu: {e}")
                clear_session_state()
    else:
        st.warning("LÃ¼tfen 'Analizi BaÅŸlat' butonuna basmadan Ã¶nce AdÄ±m 2'de bir dosya yÃ¼kleyin.")

# --- Sekmeleri Doldurma ---
if 'analysis_results' in st.session_state and 'df_for_tabs' in st.session_state:
    results = st.session_state.analysis_results
    df_display = st.session_state.df_for_tabs
    charts = st.session_state.get('charts_dict', {}) 
    
    if results.get('error'):
        with tab_analiz: 
            st.error(results['error'])
        with tab_dashboard:
            st.error(f"Analiz baÅŸarÄ±sÄ±z olduÄŸu iÃ§in dashboard oluÅŸturulamadÄ±: {results['error']}")
    else:
        with tab_dashboard:
            display_dashboard_tab(df_display, charts)
        with tab_analiz:
            display_analysis_tab(results, charts)
else:
    with tab_dashboard:
        st.info("Veri setinin gÃ¶rsel Ã¶zetini gÃ¶rmek iÃ§in lÃ¼tfen sol menÃ¼deki adÄ±mlarÄ± izleyin.")
    with tab_analiz:
        st.info("Ä°statistiksel analiz raporunu gÃ¶rmek iÃ§in lÃ¼tfen sol menÃ¼deki adÄ±mlarÄ± izleyin.")
